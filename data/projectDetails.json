[
    {
        "title": "WikiMapper (Current)",
        "description": "<p>The WikiMapper project was inspired by the Wikipedia game where you have to traverse from one page of the site to another in as few jumps as possible using the links on the page.\n A simple C++ Wikipedia XML file parser was written to extract the pages (graph nodes) and their associated links (graph edges) into a Neo4j database using the Neo4j-admin tool. This program was parallelised, dropping the execution time to process the 100GB XML file by 70%.\nThe built-in Neo4j tool allows for some basic visualisation, however due to the sheer size of the database (over 300 million links) it was only able to represent a very small subsection of the graph.\n\nFor this reason I am developing a 3D visualiser in OpenGL, using imposter Cylinders and imposter Spheres to reduce the number of vertices being rendered. Compute shaders have also been implemented to reduce the amount of data being sent to the GPU.</p> <img class=\"resizable-image\" src=\" assets/wikimapper.png\"> <p>Above is an image of the visualiser that is (hopefully) somewhat recent. The Cylinders and Sphere imposters took a long time to get working properly, but it means that each sphere and cylinder only consits of 4 vertices which is very important when there hundreds of thousands of them. [Project Repo](https://github.com/ejagombar/WikiMapper) </div>"
    },
    {
        "title": "Home Server",
        "description": "<p>The initial goal of this project was to self host a HA Kubernetes cluster to learn more about it. I designed and built a compact rack based off some Lenovo Mini PCs. After setting up K3S, I decided that Kubernetes was more effort than it was worth for a homelab environment and instead opted to set up a Proxmox server, where I hosted a number of services such as a VPN, Home Assistant, and my Spanner project. Now I am working on building a new and improved version of the server. \n\nBelow are some pictures of the finished server. The case was designed in Fusion360, and the rack contains an integrated switch and the power supplies, so it can all be powered via a single cable.</p>"
    },
    {
        "title": "Spanner",
        "description": "<p>Spanner is a website that allows users to analyse their listening habits and playlists. I undertook this project to learn a bit of web development, and another justification for building my home server. The frontend was developed in Typescript with React. The backend, which communicates with the Spotify API and processes the data, was developed in Go.</p>"
    },
    {
        "title": "Gesture Controlled Robot Hand",
        "description": "<p>For my master's project, I developed a gesture-controlled robotic hand. I designed and 3D printed a hand with 6 degrees of motion. A microcontroller embedded in the hand is sent data from a Raspberry Pi, which receives finger position data via a UDP server from a desktop application. The desktop application utilizes computer vision to track the user's hand.\n\n For my master's project, I developed a gesture-controlled robotic hand. I designed and 3D printed a hand with 6 degrees of motion. A microcontroller embedded in the hand is sent data from a Raspberry Pi, which receives finger position data via a UDP server from a desktop application. The desktop application utilizes computer vision to track the user's hand.</p><div class=\"videoWrapper\"> <iframe src=\"https://www.youtube-nocookie.com/embed/uO_aIPs5To0?si=ACphi8zCP0spFiy9&amp;controls=0autoplay=1&mute=1\" allowfullscreen></iframe> </div><p> The desktop application was developed in Qt and implemented Googleâ€™s machine learning MediaPipe library for the hand tracking. This data was translated into servo positions and sent over the internet via my server to the robotic hand. I was able to reduce the total system (including the hand tracking) latency to 320ms.</p>"
    },
    {
        "title": "Table Football Robot",
        "description": "<p>At the Nottingham 24 hour Hackathon - HackNotts84, I led a team to win Intel's 1st place prize, building a table football robot and competing against over 40 teams from 25 universities across the UK.\n\nThis was achieved using computer vision and parts of a 3D printer. </p> <div class=\"videoWrapper\"> <iframe src=\"https://www.youtube-nocookie.com/embed/nU2mIn70Abg?si=OpaB1VN8p0i3ZOnH&amp;controls=0autoplay=1&mute=1\" allowfullscreen></iframe> </div><p>We were able to track the location of the ball in real time using a webcam and OpenCV and send Gcode commands to the robot control board in order to intercept and kick the ball towards the goal.</p>"
    }
]
