[
    {
        "title": "WikiMapper (Current)",
        "description": "<p>Detailed description for Project A. Lorem s the Gaussian curve has a larger area close to its center, using its values as weights to blur an image give more natural results as samples close by have a higher precedence. If we for instance sample a 32x32 box around a fragment, we use progressively smaller weights the larger the distance to the fragment; this gives a better and more realistic blur which is known as a Gaussian blur. To implement a Gaussian blur filter we'd need a two-dimensional box of weights that we can obtain from a 2 dimensional Gaussian curve equation. The problem with this approach however is that it quickly becomes extremely heavy on performance. Take a blur kernel of 32 by 32 for example, this would require us to sample a texture a total of 1024 times for each fragment! Luckily for us, the Gaussian equation has a very neat property that allows us to separate the two-dimensional equation into two smaller one-dimensional equations: one that describes the horizontal weights and the other that describes the vertical weights. We'd then first do a horizontal blur with the horizontal weights on the scene texture, and then on the resulting texture do a vertical blur. Due to this property the results are exactly the same, but this time saving us an incredible amount of performance as we'd now only have to do 32 + 32 s the Gaussian curve has a larger area close to its center, using its values as weights to blur an image give more natural results as samples close by have a higher precedence. If we for instance sample a 32x32 box around a fragment, we use progressively smaller weights the larger the distance to the fragment; this gives a better and more realistic blur which is known as a Gaussian blur. To implement a Gaussian blur filter we'd need a two-dimensional box of weights that we can obtain from a 2 dimensional Gaussian curve equation. The problem with this approach however is that it quickly becomes extremely heavy on performance. Take a blur kernel of 32 by 32 for example, this would require us to sample a texture a total of 1024 times for each fragment! Luckily for us, the Gaussian equation has a very neat property that allows us to separate the two-dimensional equation into two smaller one-dimensional equations: one that describes the horizontal weights and the other that describes the vertical weights. We'd then first do a horizontal blur with the horizontal weights on the scene texture, and then on the resulting texture do a vertical blur. Due to this property the results are exactly the same, but this time saving us an incredible amount of performance as we'd now only have to do 32 + 32 There are many potential optimisations with this project. At the moment, I am focusing on adding new features and performance will be slightly sidelined. Some important performance choices have been made, such as using imposter spheres instead of sphere meshes. This allows for 500,000 of spheres to be created and run at over 200fps. However, many optimisations have been left to later. One of the main reasons for this is to allow me to implement new features faster and eventaully compare the performance between the future optimised version and non-optimised version. </p>"
    },
    {
        "title": "Home Server",
        "description": "AAfter completing an internship in a cloud infrastructure department, I decided to build my own home server. I wanted to learn more about cloud infrastructure, as well as having a place to host my own projects. Initially, I set up a Kubernetes cluster to learn more about it. However, I eventually settled on using Proxmox to manage containers and VMs.After completing an internship in a cloud infrastructure department, I decided to build my own home server. I wanted to learn more about cloud infrastructure, as well as having a place to host my own projects. Initially, I set up a Kubernetes cluster to learn more about it. However, I eventually settled on using Proxmox to manage containers and VMs.fter completing an internship in a cloud infrastructure department, I decided to build my own home server. I wanted to learn more about cloud infrastructure, as well as having a place to host my own projects. Initially, I set up a Kubernetes cluster to learn more about it. However, I eventually settled on using Proxmox to manage containers and VMs."
    },
    {
        "title": "Spanner",
        "description": "Spanner Spanner is a website that allows users to analyze their listening habits and playlists. I undertook this project to learn about web development, gain some experience on the front end, as well as giving me an excuse to build a server to host the site! The frontend was developed in Typescript with React. The backend, which communicates with the Spotify API and processes the data, was developed in Go.Spanner is a website that allows users to analyze their listening habits and playlists. I undertook this project to learn about web development, gain some experience on the front end, as well as giving me an excuse to build a server to host the site! The frontend was developed in Typescript with React. The backend, which communicates with the Spotify API and processes the data, was developed in Go.is a website that allows users to analyze their listening habits and playlists. I undertook this project to learn about web development, gain some experience on the front end, as well as giving me an excuse to build a server to host the site! The frontend was developed in Typescript with React. The backend, which communicates with the Spotify API and processes the data, was developed in Go."
    },
    {
        "title": "Gesture Controlled Robot Hand",
        "description": "FFor my master's project, I developed a gesture-controlled robotic hand. I designed and 3D printed a hand with 6 degrees of motion, controlled via a microcontroller. The microcontroller receives data from a Raspberry Pi, which receives position data via UDP from a desktop application that I developed in QT over the internet. The desktop application utilizes computer vision to track the user's hand with a webcam and the MediaPipe library.For my master's project, I developed a gesture-controlled robotic hand. I designed and 3D printed a hand with 6 degrees of motion, controlled via a microcontroller. The microcontroller receives data from a Raspberry Pi, which receives position data via UDP from a desktop application that I developed in QT over the internet. The desktop application utilizes computer vision to track the user's hand with a webcam and the MediaPipe library.or my master's project, I developed a gesture-controlled robotic hand. I designed and 3D printed a hand with 6 degrees of motion, controlled via a microcontroller. The microcontroller receives data from a Raspberry Pi, which receives position data via UDP from a desktop application that I developed in QT over the internet. The desktop application utilizes computer vision to track the user's hand with a webcam and the MediaPipe library."
    },
    {
        "title": "Table Football Robot",
        "description": "AtAt the Nottingham 24 hour Hackathon - HackNotts84, I led a team to win Intel's 1st place prize, building a table football robot and competing against over 40 teams from 25 universities across the UK.\n\nThis was achieved using computer vision and parts of a 3D printer. We were able to track the location of the ball in real time using a webcam and OpenCV and send Gcode commands to the robot control board in order to intercept and kick the ball towards the goal.At the Nottingham 24 hour Hackathon - HackNotts84, I led a team to win Intel's 1st place prize, building a table football robot and competing against over 40 teams from 25 universities across the UK.\n\nThis was achieved using computer vision and parts of a 3D printer. We were able to track the location of the ball in real time using a webcam and OpenCV and send Gcode commands to the robot control board in order to intercept and kick the ball towards the goal. the Nottingham 24 hour Hackathon - HackNotts84, I led a team to win Intel's 1st place prize, building a table football robot and competing against over 40 teams from 25 universities across the UK.\n\nThis was achieved using computer vision and parts of a 3D printer. We were able to track the location of the ball in real time using a webcam and OpenCV and send Gcode commands to the robot control board in order to intercept and kick the ball towards the goal."
    }
]
